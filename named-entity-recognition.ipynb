{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers datasets seqeval","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-12T03:56:54.472471Z","iopub.execute_input":"2025-07-12T03:56:54.472700Z","iopub.status.idle":"2025-07-12T03:57:03.819353Z","shell.execute_reply.started":"2025-07-12T03:56:54.472678Z","shell.execute_reply":"2025-07-12T03:57:03.818442Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset\n\nds = load_dataset(\"conll2003\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T03:57:33.661733Z","iopub.execute_input":"2025-07-12T03:57:33.662262Z","iopub.status.idle":"2025-07-12T03:57:42.237086Z","shell.execute_reply.started":"2025-07-12T03:57:33.662231Z","shell.execute_reply":"2025-07-12T03:57:42.236559Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"547c61001a454c41862ac70abba4225f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"conll2003.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d3ca4ff244d49ef92c2f9a2565548fc"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for conll2003 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/conll2003.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a4fa35e852a4761a145f0b2a7aa80c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba8888ffd50440a69d30bdeb0cdfb26e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8c2e1876bff46e5af16b807c535660e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecda7d40e1024ac8899806fb726f7858"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T03:58:03.353250Z","iopub.execute_input":"2025-07-12T03:58:03.353918Z","iopub.status.idle":"2025-07-12T03:58:03.358928Z","shell.execute_reply.started":"2025-07-12T03:58:03.353892Z","shell.execute_reply":"2025-07-12T03:58:03.358249Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 14041\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3250\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3453\n    })\n})"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import os\nos.environ['WANDB_DISABLED'] = 'true'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T03:59:31.789731Z","iopub.execute_input":"2025-07-12T03:59:31.790017Z","iopub.status.idle":"2025-07-12T03:59:31.793726Z","shell.execute_reply.started":"2025-07-12T03:59:31.789996Z","shell.execute_reply":"2025-07-12T03:59:31.793036Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"label_list = ds['train'].features['ner_tags'].feature.names\nid2label = {i : label for i,label in enumerate(label_list)}\nlabel2id = {label : i for i,label in enumerate(label_list)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T03:59:36.737843Z","iopub.execute_input":"2025-07-12T03:59:36.738121Z","iopub.status.idle":"2025-07-12T03:59:36.742941Z","shell.execute_reply.started":"2025-07-12T03:59:36.738098Z","shell.execute_reply":"2025-07-12T03:59:36.742265Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from transformers import AutoTokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T03:59:37.677843Z","iopub.execute_input":"2025-07-12T03:59:37.678087Z","iopub.status.idle":"2025-07-12T03:59:49.605229Z","shell.execute_reply.started":"2025-07-12T03:59:37.678069Z","shell.execute_reply":"2025-07-12T03:59:49.604430Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T03:59:53.233789Z","iopub.execute_input":"2025-07-12T03:59:53.234287Z","iopub.status.idle":"2025-07-12T03:59:54.060040Z","shell.execute_reply.started":"2025-07-12T03:59:53.234261Z","shell.execute_reply":"2025-07-12T03:59:54.059138Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7067c3edc3a749ddacf5de9d45c9fc41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf8a61aeaf3a42a8917da2cc18267f10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"788dc43f79394144ade346a7f572dee0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcdffce89b7c43ca9bef1dd1753c9c89"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"def tokenize_labels(examples):\n    tokenized_inputs = tokenizer(examples['tokens'],\n                                truncation=True,\n                                is_split_into_words=True)\n    labels = []\n    for i,label in enumerate(examples['ner_tags']):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        previous_word_idx=None\n        label_ids = []\n        for word_idx in word_ids:\n            if word_idx is None:\n                label_ids.append(-100)\n            elif word_idx != previous_word_idx:\n                label_ids.append(label[word_idx])\n            else:\n                label_ids.append(-100)\n            previous_word_idx = word_idx\n        labels.append(label_ids)\n    tokenized_inputs['labels'] = labels\n    return tokenized_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T03:59:55.773835Z","iopub.execute_input":"2025-07-12T03:59:55.774628Z","iopub.status.idle":"2025-07-12T03:59:55.779786Z","shell.execute_reply.started":"2025-07-12T03:59:55.774601Z","shell.execute_reply":"2025-07-12T03:59:55.779001Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"tokenized_dataset = ds.map(tokenize_labels,batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T03:59:58.038019Z","iopub.execute_input":"2025-07-12T03:59:58.038402Z","iopub.status.idle":"2025-07-12T04:00:00.516333Z","shell.execute_reply.started":"2025-07-12T03:59:58.038366Z","shell.execute_reply":"2025-07-12T04:00:00.515469Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14041 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0648d0dc37fb402987649e8b1afd13e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"989ee2b18ae640e18cd681f58933a808"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbb76d76b35b40a9952c47632e71d687"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"from transformers import AutoModelForTokenClassification \nmodel = AutoModelForTokenClassification.from_pretrained(\n    'bert-base-cased',\n    num_labels = len(label_list),\n    id2label = id2label,\n    label2id = label2id\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T04:00:02.026157Z","iopub.execute_input":"2025-07-12T04:00:02.026437Z","iopub.status.idle":"2025-07-12T04:00:29.800054Z","shell.execute_reply.started":"2025-07-12T04:00:02.026417Z","shell.execute_reply":"2025-07-12T04:00:29.799336Z"}},"outputs":[{"name":"stderr","text":"2025-07-12 04:00:10.967913: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752292811.346820      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752292811.461121      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1eef054eaa442b6aa7d5c1ee84a9047"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"!pip install -q evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T04:00:29.801203Z","iopub.execute_input":"2025-07-12T04:00:29.802118Z","iopub.status.idle":"2025-07-12T04:00:33.505108Z","shell.execute_reply.started":"2025-07-12T04:00:29.802084Z","shell.execute_reply":"2025-07-12T04:00:33.504074Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from transformers import TrainingArguments,Trainer \nimport evaluate ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T04:00:42.546340Z","iopub.execute_input":"2025-07-12T04:00:42.547247Z","iopub.status.idle":"2025-07-12T04:00:45.518632Z","shell.execute_reply.started":"2025-07-12T04:00:42.547207Z","shell.execute_reply":"2025-07-12T04:00:45.517836Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"metric = evaluate.load(\"seqeval\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T04:00:45.519957Z","iopub.execute_input":"2025-07-12T04:00:45.520240Z","iopub.status.idle":"2025-07-12T04:00:45.965411Z","shell.execute_reply.started":"2025-07-12T04:00:45.520215Z","shell.execute_reply":"2025-07-12T04:00:45.964677Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf5a800d20d94322b222fdf7bf5b4808"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"def compute_metrics(p):\n    predictions, labels = p\n    predictions = predictions.argmax(-1)\n\n    true_predictions = [\n        [label_list[p] for (p, l) in zip(pred, label) if l != -100]\n        for pred, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [label_list[l] for (p, l) in zip(pred, label) if l != -100]\n        for pred, label in zip(predictions, labels)\n    ]\n    \n    results = metric.compute(predictions=true_predictions, references=true_labels)\n\n    return {\n        \"precision\": results[\"overall_precision\"],\n        \"recall\": results[\"overall_recall\"],\n        \"f1\": results[\"overall_f1\"],\n        \"accuracy\": results[\"overall_accuracy\"]\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T04:06:31.731494Z","iopub.execute_input":"2025-07-12T04:06:31.731814Z","iopub.status.idle":"2025-07-12T04:06:31.738095Z","shell.execute_reply.started":"2025-07-12T04:06:31.731791Z","shell.execute_reply":"2025-07-12T04:06:31.737359Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"args = TrainingArguments(\n    'bert-ner',\n    eval_strategy = 'epoch',\n    save_strategy='epoch',\n    logging_strategy='steps',\n    logging_steps=1,\n    learning_rate = 2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    \n    num_train_epochs=3,\n    weight_decay=0.01\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T04:11:33.413385Z","iopub.execute_input":"2025-07-12T04:11:33.413705Z","iopub.status.idle":"2025-07-12T04:11:33.449397Z","shell.execute_reply.started":"2025-07-12T04:11:33.413679Z","shell.execute_reply":"2025-07-12T04:11:33.448684Z"}},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"from transformers import DataCollatorForTokenClassification\ndata_collator = DataCollatorForTokenClassification(tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T04:11:50.945902Z","iopub.execute_input":"2025-07-12T04:11:50.946555Z","iopub.status.idle":"2025-07-12T04:11:50.950656Z","shell.execute_reply.started":"2025-07-12T04:11:50.946524Z","shell.execute_reply":"2025-07-12T04:11:50.949904Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    args,\n    train_dataset=tokenized_dataset['train'],\n    eval_dataset = tokenized_dataset['validation'],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics = compute_metrics\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T04:11:53.125303Z","iopub.execute_input":"2025-07-12T04:11:53.126017Z","iopub.status.idle":"2025-07-12T04:11:53.144177Z","shell.execute_reply.started":"2025-07-12T04:11:53.125982Z","shell.execute_reply":"2025-07-12T04:11:53.143494Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/2459668089.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T04:11:54.845450Z","iopub.execute_input":"2025-07-12T04:11:54.846206Z","iopub.status.idle":"2025-07-12T04:18:25.008675Z","shell.execute_reply.started":"2025-07-12T04:11:54.846172Z","shell.execute_reply":"2025-07-12T04:18:25.008054Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1317' max='1317' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1317/1317 06:29, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.014300</td>\n      <td>0.040425</td>\n      <td>0.938649</td>\n      <td>0.944968</td>\n      <td>0.941798</td>\n      <td>0.990168</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.000900</td>\n      <td>0.042111</td>\n      <td>0.939181</td>\n      <td>0.945978</td>\n      <td>0.942567</td>\n      <td>0.990343</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.019200</td>\n      <td>0.041622</td>\n      <td>0.944704</td>\n      <td>0.951700</td>\n      <td>0.948189</td>\n      <td>0.990986</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1317, training_loss=0.012681161963476162, metrics={'train_runtime': 389.6023, 'train_samples_per_second': 108.118, 'train_steps_per_second': 3.38, 'total_flos': 1164123671696082.0, 'train_loss': 0.012681161963476162, 'epoch': 3.0})"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"from transformers import pipeline \nner_pipeline = pipeline(\"ner\",\n                       model=model,\n                       tokenizer=tokenizer,\n                       aggregation_strategy='simple')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T04:21:01.731270Z","iopub.execute_input":"2025-07-12T04:21:01.731957Z","iopub.status.idle":"2025-07-12T04:21:01.737125Z","shell.execute_reply.started":"2025-07-12T04:21:01.731929Z","shell.execute_reply":"2025-07-12T04:21:01.736363Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"ner_pipeline(\"I don't thing Apple has anything to do with Manhattan\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T04:21:39.361336Z","iopub.execute_input":"2025-07-12T04:21:39.361773Z","iopub.status.idle":"2025-07-12T04:21:39.496015Z","shell.execute_reply.started":"2025-07-12T04:21:39.361748Z","shell.execute_reply":"2025-07-12T04:21:39.495188Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"[{'entity_group': 'ORG',\n  'score': 0.99906486,\n  'word': 'Apple',\n  'start': 14,\n  'end': 19},\n {'entity_group': 'LOC',\n  'score': 0.99849415,\n  'word': 'Manhattan',\n  'start': 44,\n  'end': 53}]"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"model.save_pretrained('ner-bert-model')\ntokenizer.save_pretrained('ner-bert-model')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T04:25:23.994265Z","iopub.execute_input":"2025-07-12T04:25:23.994896Z","iopub.status.idle":"2025-07-12T04:25:24.889138Z","shell.execute_reply.started":"2025-07-12T04:25:23.994872Z","shell.execute_reply":"2025-07-12T04:25:24.888431Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"('ner-bert-model/tokenizer_config.json',\n 'ner-bert-model/special_tokens_map.json',\n 'ner-bert-model/vocab.txt',\n 'ner-bert-model/added_tokens.json',\n 'ner-bert-model/tokenizer.json')"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"import shutil \nmodel_dir = '/kaggle/working/ner-bert-model'\nshutil.make_archive(model_dir,'zip',model_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-12T04:26:51.189158Z","iopub.execute_input":"2025-07-12T04:26:51.189430Z","iopub.status.idle":"2025-07-12T04:27:12.976025Z","shell.execute_reply.started":"2025-07-12T04:26:51.189409Z","shell.execute_reply":"2025-07-12T04:27:12.975282Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/ner-bert-model.zip'"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}